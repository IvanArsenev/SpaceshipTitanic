{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_test = pd.read_csv('train.csv'), pd.read_csv('test.csv')  \n",
    "X_train, y_train = train.iloc[:, :-1], train.iloc[:, -1:]\n",
    "\n",
    "y_train_ = y_train.astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_feature(df, feature, new_features, sep):\n",
    "    df[new_features] = df[feature].str.split(sep, expand=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df, features):\n",
    "    df.drop(features, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_feature(df, feature, cast):\n",
    "    df[feature] = df[feature].astype(cast)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = split_feature(X_test, 'PassengerId', ['GroupId', 'IdWithinGroup'], '_')\n",
    "X_train = split_feature(X_train, 'PassengerId', ['GroupId', 'IdWithinGroup'], '_')\n",
    "\n",
    "X_test = split_feature(X_test, 'Cabin', ['Deck', 'Num', 'Side'], '/')\n",
    "X_train = split_feature(X_train, 'Cabin', ['Deck', 'Num', 'Side'], '/')\n",
    "\n",
    "X_test = drop_features(X_test, ['Name', 'PassengerId', 'Cabin', 'VIP', 'Num'])\n",
    "X_train = drop_features(X_train, ['Name', 'PassengerId', 'Cabin', 'VIP', 'Num'])\n",
    "\n",
    "X_test = cast_feature(X_test, 'GroupId', 'float')\n",
    "X_train = cast_feature(X_train, 'GroupId', 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet       201\n",
       "CryoSleep        217\n",
       "Destination      182\n",
       "Age              179\n",
       "RoomService      181\n",
       "FoodCourt        183\n",
       "ShoppingMall     208\n",
       "Spa              183\n",
       "VRDeck           188\n",
       "GroupId            0\n",
       "IdWithinGroup      0\n",
       "Deck             199\n",
       "Side             199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Deck</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Earth</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europa</th>\n",
       "      <td>252.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mars</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck            A      B      C      D      E       F       G    T\n",
       "HomePlanet                                                        \n",
       "Earth         0.0    0.0    0.0    0.0  395.0  1614.0  2498.0  0.0\n",
       "Europa      252.0  766.0  734.0  186.0  128.0     0.0     0.0  4.0\n",
       "Mars          0.0    0.0    0.0  282.0  330.0  1110.0     0.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_planet_deck = X_train.groupby(['HomePlanet', 'Deck']).size().unstack().fillna(0)\n",
    "home_planet_deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_cryo_sleep(df):\n",
    "    df.loc[\n",
    "        ((df['RoomService'] == 0.0) | df['RoomService'].isnull()) & \n",
    "        ((df['FoodCourt'] == 0.0) | df['FoodCourt'].isnull()) & \n",
    "        ((df['ShoppingMall'] == 0.0) | df['ShoppingMall'].isnull()) & \n",
    "        ((df['Spa'] == 0.0) | df['Spa'].isnull()) &\n",
    "        ((df['VRDeck'] == 0.0) | df['VRDeck'].isnull()) &\n",
    "        (df['CryoSleep'].isnull()), \n",
    "        'CryoSleep'\n",
    "    ] = True\n",
    "    \n",
    "    df.loc[\n",
    "        ((df['RoomService'] > 0.0) | \n",
    "        (df['FoodCourt'] > 0.0) | \n",
    "        (df['ShoppingMall'] > 0.0) | \n",
    "        (df['Spa'] > 0.0) |\n",
    "        (df['VRDeck'] > 0.0)) & (df['CryoSleep'].isnull()), \n",
    "        'CryoSleep'\n",
    "    ] = False\n",
    "    return df\n",
    "\n",
    "X_train = impute_cryo_sleep(X_train)\n",
    "X_test = impute_cryo_sleep(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_home_planet_by_deck(df):\n",
    "    df.loc[\n",
    "        (df['Deck'] == 'G') & (df['HomePlanet'].isnull()), \n",
    "        'HomePlanet'\n",
    "    ] = 'Earth'\n",
    "    \n",
    "    europa_decks = ['A', 'B', 'C', 'T']\n",
    "    df.loc[\n",
    "        (df['Deck'].isin(europa_decks)) & (df['HomePlanet'].isnull()), \n",
    "        'HomePlanet'\n",
    "    ] = 'Europa'\n",
    "    df.loc[\n",
    "        (df['Deck'] == 'F') & (df['HomePlanet'].isnull()), \n",
    "        'HomePlanet'\n",
    "    ] = 'Mars'\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train = impute_home_planet_by_deck(X_train)\n",
    "X_test = impute_home_planet_by_deck(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_planet_deck = X_train.groupby(['HomePlanet', 'Deck']).size().unstack().fillna(0)\n",
    "\n",
    "earth = home_planet_deck.loc['Earth']\n",
    "earth_proba = list(earth / sum(earth))\n",
    "\n",
    "europa = home_planet_deck.loc['Europa']\n",
    "europa_proba = list(europa / sum(europa))\n",
    "\n",
    "mars = home_planet_deck.loc['Mars']\n",
    "mars_proba = list(mars / sum(mars))\n",
    "\n",
    "decks = X_train['Deck'].unique()\n",
    "deck_values = sorted(decks[~pd.isnull(decks)]) #['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "planet_proba = dict(zip(['Earth', 'Mars', 'Europa'], [earth_proba, mars_proba, europa_proba]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(240304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_deck_by_home_planet(df):\n",
    "    for planet in planet_proba.keys():\n",
    "        planet_null_decks_shape = df.loc[(df['HomePlanet'] == planet) & (df['Deck'].isnull()), 'Deck'].shape[0]\n",
    "        df.loc[(df['HomePlanet'] == planet) & (df['Deck'].isnull()), 'Deck'] = np.random.choice(deck_values, planet_null_decks_shape, p=planet_proba[planet]) \n",
    "    return df\n",
    "               \n",
    "X_train = impute_deck_by_home_planet(X_train)\n",
    "X_test = impute_deck_by_home_planet(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age_by_planet(df):\n",
    "    for planet in ['Europa', 'Earth', 'Mars']:\n",
    "        planet_median = df[df['HomePlanet'] == planet]['Age'].median()\n",
    "        df.loc[(df[\"Age\"].isnull()) & (df[\"HomePlanet\"] == planet),\"Age\"] = planet_median\n",
    "    return df\n",
    "\n",
    "X_train = impute_age_by_planet(X_train)\n",
    "X_test = impute_age_by_planet(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet        39\n",
       "CryoSleep          0\n",
       "Destination      182\n",
       "Age                0\n",
       "RoomService      181\n",
       "FoodCourt        183\n",
       "ShoppingMall     208\n",
       "Spa              183\n",
       "VRDeck           188\n",
       "GroupId            0\n",
       "IdWithinGroup      0\n",
       "Deck               6\n",
       "Side             199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_usluga_by_age(df):\n",
    "    uniq_age = df['Age'].unique()\n",
    "    uslugi = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for age in uniq_age:\n",
    "        for usluga in uslugi:\n",
    "            usluga_median = df[df['Age'] == age][usluga].median()\n",
    "            df.loc[(df[usluga].isnull()) & (df['Age'] == age), usluga] = usluga_median\n",
    "    return df\n",
    "\n",
    "X_train = impute_usluga_by_age(X_train)\n",
    "X_test = impute_usluga_by_age(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet        39\n",
       "CryoSleep          0\n",
       "Destination      182\n",
       "Age                0\n",
       "RoomService        0\n",
       "FoodCourt          0\n",
       "ShoppingMall       0\n",
       "Spa                0\n",
       "VRDeck             0\n",
       "GroupId            0\n",
       "IdWithinGroup      0\n",
       "Deck               6\n",
       "Side             199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = X_train.describe().columns\n",
    "categorical_columns = set(X_train.columns) - set(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    si = SimpleImputer(strategy='median')\n",
    "    X_train[col] = si.fit_transform(X_train[col].values.reshape(-1, 1))\n",
    "    X_test[col] = si.fit_transform(X_test[col].values.reshape(-1, 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    si = SimpleImputer(strategy='most_frequent')\n",
    "    X_train[[col]] = si.fit_transform(X_train[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_data(df):\n",
    "    for col in numerical_columns[1:-1]:\n",
    "        df[col] = np.log(1 + df[col])\n",
    "    return df\n",
    "\n",
    "X_train = log_transform_data(X_train)\n",
    "X_test = log_transform_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = pd.get_dummies(X_train)\n",
    "X_test_ = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7741490340386384 for num_epochs = 64 seed = 205282\n",
      "Accuracy on test set: 0.7764489420423183 for num_epochs = 64 seed = 273780\n",
      "Accuracy on test set: 0.781048758049678 for num_epochs = 64 seed = 285812\n",
      "Accuracy on test set: 0.7842686292548298 for num_epochs = 64 seed = 330951\n",
      "Accuracy on test set: 0.7888684452621895 for num_epochs = 64 seed = 294690\n",
      "Accuracy on test set: 0.7930082796688133 for num_epochs = 64 seed = 56632\n",
      "Accuracy on test set: 0.7994480220791168 for num_epochs = 64 seed = 419034\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "best_model = None\n",
    "while best_acc<0.81:\n",
    "    seed = random.randint(0, 500000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_, y_train_, test_size=0.25, random_state=seed)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Преобразуйте DataFrame целевой переменной в массив NumPy\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "    \n",
    "    # Преобразование массивов NumPy в тензоры PyTorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    class TitanicClassifier(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super(TitanicClassifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "        def forward(self, x):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            out = self.fc2(out)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "    # Инициализация модели, функции потерь и оптимизатора\n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = 64\n",
    "    output_size = 1\n",
    "    model = TitanicClassifier(input_size, hidden_size, output_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Обучение модели\n",
    "\n",
    "    for epoch in range(10, 150):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Оценка модели на тестовом наборе данных\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())\n",
    "        \n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_model = model\n",
    "        print(f'Accuracy on test set: {accuracy} for num_epochs = {num_epochs} seed = {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение прямого прохода (forward pass) через модель для тестового набора данных\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predicted = (outputs > 0.5).float()  # Преобразование вероятностей в бинарные значения (0 или 1)\n",
    "# Создание DataFrame с предсказанными значениями\n",
    "sub = pd.DataFrame()\n",
    "sub['PassengerId'] = pd.read_csv('test.csv')['PassengerId']  # Предположим, что в вашем тестовом CSV файле есть столбец 'PassengerId'\n",
    "sub['Transported'] = pd.Series(predicted.numpy().flatten()).astype(bool)  # Преобразование предсказанных значений в тип bool\n",
    "\n",
    "# Сохранение предсказанных значений в CSV файл\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7549673,
     "sourceId": 67997,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
